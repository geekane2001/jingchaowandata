import asyncio
import base64
import json
import logging
import os
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
import uvicorn

from playwright.async_api import async_playwright, Page
from openai import AsyncOpenAI
from playwright._impl._errors import TimeoutError as PlaywrightTimeoutError

logging.basicConfig(level=logging.INFO, format='%(asctime)s - [%(levelname)s] - %(message)s')

TARGET_URL = "https://www.life-data.cn/?channel_id=laike_data_first_menu&groupid=1768205901316096"
SCREENSHOT_PATH = "dashboard_screenshot.png"
DEBUG_SCREENSHOT_PATH = "debug_screenshot.png"
REFRESH_INTERVAL_SECONDS = 10

LIFE_DATA_COOKIE_VALUE = os.getenv("LIFE_DATA_COOKIE")
API_KEY = os.getenv("OPENAI_API_KEY", "bae85abf-09f0-4ea3-9228-1448e58549fc")

client = AsyncOpenAI(
    base_url='https://api-inference.modelscope.cn/v1/',
    api_key=API_KEY,
)
MODEL_ID = 'Qwen/Qwen2.5-VL-7B-Instruct' 

app_state = {"latest_data": None, "status": "Initializing..."}

# ... (æ‰€æœ‰å…¶ä»–å‡½æ•° get_detailed_prompt, encode_image_to_base64, analyze_image_with_vlm, wait_for_data_to_load, run_playwright_scraper éƒ½ä¿æŒä¸å˜) ...
def get_detailed_prompt():
    return """
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆã€‚è¯·åˆ†æè¿™å¼ ä»ªè¡¨ç›˜æˆªå›¾ï¼Œå¹¶æå–æ‰€æœ‰å…³é”®æŒ‡æ ‡å¡ç‰‡çš„ä¿¡æ¯ã€‚
    ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–Markdownæ ‡è®°ã€‚
    { "update_time": "...", "comparison_date": "...", "metrics": [ { "name": "...", "value": "...", "comparison": "...", "status": "..." } ] }
    è¯·ç¡®ä¿ï¼š
    1. **åªæå–ä»¥ä¸‹æŒ‡æ ‡**ï¼šæˆäº¤é‡‘é¢ã€æ ¸é”€é‡‘é¢ã€å•†å“è®¿é—®äººæ•°ã€æ ¸é”€åˆ¸æ•°ã€‚
    2. **å¿½ç•¥â€œé€€æ¬¾é‡‘é¢â€** ä»¥åŠå…¶ä»–æ‰€æœ‰æœªåˆ—å‡ºçš„æŒ‡æ ‡ã€‚
    3. æ‰€æœ‰å­—æ®µéƒ½ä»å›¾ç‰‡ä¸­å‡†ç¡®æå–ã€‚
    """
def encode_image_to_base64(image_path: str) -> str:
    try:
        with open(image_path, "rb") as image_file: return base64.b64encode(image_file.read()).decode('utf-8')
    except FileNotFoundError: return ""
async def analyze_image_with_vlm(image_base64: str) -> dict:
    if not image_base64: return {}
    try:
        response = await client.chat.completions.create( model=MODEL_ID, messages=[{'role': 'user', 'content': [{'type': 'text', 'text': get_detailed_prompt()}, {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{image_base64}'}}],}])
        raw_content = response.choices[0].message.content
        if raw_content.startswith("```json"): raw_content = raw_content[7:-3].strip()
        return json.loads(raw_content)
    except Exception as e: logging.error(f"è°ƒç”¨è§†è§‰æ¨¡å‹æˆ–è§£æJSONæ—¶å‡ºé”™: {e}"); return {}
async def wait_for_data_to_load(page: Page, timeout: int = 60000):
    logging.info("æ­£åœ¨æ™ºèƒ½ç­‰å¾…é¡µé¢æ•°æ®åŠ è½½...")
    try:
        await page.wait_for_function("() => document.querySelector('div[class*=\"index-module_value_\"]') && document.querySelector('div[class*=\"index-module_value_\"]').innerText.trim() !== '0'", timeout=timeout)
        logging.info("å…³é”®æ•°æ®å·²åŠ è½½ï¼Œé¡µé¢å‡†å¤‡å°±ç»ªï¼"); return True
    except PlaywrightTimeoutError: logging.error(f"æ™ºèƒ½ç­‰å¾…è¶…æ—¶ï¼ˆ{timeout/1000}ç§’ï¼‰ï¼šå…³é”®æ•°æ®æœªèƒ½åŠ è½½ã€‚"); return False
async def run_playwright_scraper():
    if not LIFE_DATA_COOKIE_VALUE: app_state["status"] = "é”™è¯¯: æœªåœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½® LIFE_DATA_COOKIEã€‚"; logging.error(app_state["status"]); return
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context()
        try:
            cookie = {"name": "satoken", "value": LIFE_DATA_COOKIE_VALUE, "domain": "www.life-data.cn", "path": "/"}; await context.add_cookies([cookie]); logging.info("æˆåŠŸé€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®satoken Cookieã€‚")
        except Exception as e: app_state["status"] = f"è®¾ç½® Cookie å¤±è´¥: {e}"; await browser.close(); return
        page = await context.new_page()
        try:
            await page.goto(TARGET_URL, wait_until="domcontentloaded", timeout=90000)
            while True:
                try:
                    logging.info("å¼€å§‹æ–°ä¸€è½®æ•°æ®åˆ·æ–°..."); await page.reload(wait_until="domcontentloaded", timeout=90000)
                    if await wait_for_data_to_load(page):
                        await page.screenshot(path=SCREENSHOT_PATH, full_page=True); image_base64 = encode_image_to_base64(SCREENSHOT_PATH)
                        if image_base64:
                            analysis_result = await analyze_image_with_vlm(image_base64)
                            if analysis_result and analysis_result.get('metrics'): app_state["latest_data"] = analysis_result; app_state["status"] = f"æ•°æ®å·²æ›´æ–°ã€‚ä¸‹ä¸€æ¬¡åˆ·æ–°åœ¨ {REFRESH_INTERVAL_SECONDS} ç§’åã€‚"
                            else: app_state["status"] = "AIåˆ†ææœªèƒ½ä»æˆªå›¾ä¸­æå–æœ‰æ•ˆæ•°æ®ã€‚"
                        else: app_state["status"] = "åˆ›å»ºæˆªå›¾å¤±è´¥ã€‚"
                    else: app_state["status"] = "ç›®æ ‡é¡µé¢æ•°æ®åŠ è½½è¶…æ—¶ã€‚"; await page.screenshot(path=DEBUG_SCREENSHOT_PATH, full_page=True)
                except Exception as e: logging.error(f"åå°ä»»åŠ¡å¾ªç¯å‘ç”Ÿé”™è¯¯: {e}"); app_state["status"] = "åå°ä»»åŠ¡å‘ç”Ÿé”™è¯¯ï¼Œæ­£åœ¨é‡è¯•..."; await page.screenshot(path=DEBUG_SCREENSHOT_PATH, full_page=True)
                await asyncio.sleep(REFRESH_INTERVAL_SECONDS)
        except PlaywrightTimeoutError as e: app_state["status"] = "è‡´å‘½é”™è¯¯: æ— æ³•æ‰“å¼€ç›®æ ‡é¡µé¢ï¼Œè¯·æ£€æŸ¥Cookieæ˜¯å¦æœ‰æ•ˆæˆ–ç›®æ ‡ç½‘ç«™æ˜¯å¦å¯è¾¾ã€‚"; logging.error(f"é¦–æ¬¡å¯¼èˆªå¤±è´¥ï¼Œä»»åŠ¡ç»ˆæ­¢: {e}", exc_info=True); await page.screenshot(path=DEBUG_SCREENSHOT_PATH, full_page=True)
        finally: await browser.close()


@asynccontextmanager
async def lifespan(app: FastAPI):
    # è®©åå°ä»»åŠ¡åœ¨å¯åŠ¨æ—¶æœ‰ä¸€ä¸ªåˆå§‹çš„ç­‰å¾…ï¼Œç¡®ä¿ç¬¬ä¸€æ¬¡æ•°æ®è·å–æœ‰æœºä¼šå®Œæˆ
    initial_delay_task = asyncio.create_task(asyncio.sleep(0)) # åªæ˜¯ä¸ºäº†åˆ›å»ºä»»åŠ¡å¯¹è±¡
    
    async def run_scraper_with_initial_flag():
        await run_playwright_scraper()
        
    scraper_task = asyncio.create_task(run_scraper_with_initial_flag())
    yield
    scraper_task.cancel()


app = FastAPI(lifespan=lifespan)

# =========================================================
# === æ ¸å¿ƒä¿®æ”¹ï¼šä¼˜åŒ–/dataæ¥å£çš„é¦–æ¬¡åŠ è½½é€»è¾‘ ===
# =========================================================
@app.get("/data")
async def get_data():
    # å³ä½¿æ•°æ®å°šæœªå°±ç»ªï¼Œä¹Ÿè¿”å›200 OKï¼Œä½†dataå†…å®¹ä¸ºnull
    # è¿™æ ·å‰ç«¯å°±ä¸ä¼šå› ä¸º404è€Œå›°æƒ‘ï¼Œè€Œæ˜¯ä¼šæ­£ç¡®åœ°æ˜¾ç¤ºâ€œæ­£åœ¨åˆå§‹åŒ–â€çš„çŠ¶æ€
    if app_state["latest_data"] is None:
        return {"status": app_state["status"], "data": None}
    return {"status": app_state["status"], "data": app_state["latest_data"]}

@app.get("/debug_screenshot")
async def get_debug_screenshot():
    if os.path.exists(DEBUG_SCREENSHOT_PATH): return FileResponse(DEBUG_SCREENSHOT_PATH)
    return HTTPException(status_code=404, detail="è°ƒè¯•æˆªå›¾ä¸å­˜åœ¨ã€‚")

app.mount("/", StaticFiles(directory=".", html=True), name="static")

if __name__ == "__main__":
    print("\n" + "="*60)
    print("      ğŸš€ ç«æ½®ç©å®æ—¶æ•°æ®çœ‹æ¿ (ä¼˜åŒ–ç‰ˆ) ğŸš€")
    print(f"\n      â¡ï¸   http://127.0.0.1:7860")
    print("="*60 + "\n")
    uvicorn.run(app, host="127.0.0.1", port=7860)
